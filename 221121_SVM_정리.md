# K-MOOC 실습으로 배우는 머신러닝 5강

## TODO
1. Support Vector Machine
2. Nonlinear SVM
3. SVM Regression

## DONE

## SVM 정의
* 선형, 비선형, 회귀, 이상치 탐색에 사용할 수 있는 다목적 머신러닝 모델.
* 주로 패턴인식 분야, 작거나 중간 크기의 데이터셋에 적합하다.
* 데이터를 선형으로 분리하는 "최적의 결정 경계" 를 찾는 알고리즘이다.
* 주어진 데이터를 바탕으로 클래스 사이의 간격, 마진(Margin)을 최대화시키는 데이터 포인트(서포트 벡터)를 찾아 유사한 그룹끼리의 칸막이 경계를 통해 데이터를 분류한다. 
* 장점: 
** 에러율이 낮다. 
** 결과를 해석하기 용이하다.
* 단점: 
** 튜닝 파라미터, 커널 선택에 민감.
** 이진 분류만 다룰 수 있다.

## 관련 용어
### 결정 경계 (Decision Boundary)
데이터를 나누는 기준 선.
분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류 과제를 수행.
결정 경계를 잘 나누었다고 할 수 있는 경우는 경계선이 각 클래스의 데이터 집합으로부터 최대한 멀리 떨어져있는 경우를 의미한다. 
만약 데이터에 2개 속성(feature)만 있다면 결정 경계는 이렇게 간단한 선 형태가 될 거다.
![image](https://user-images.githubusercontent.com/88615790/202982568-2855cffd-7e03-4387-a673-31f90ec6df9e.png)

그러나 속성이 3개로 늘어난다면 이렇게 3차원으로 그려야 한다.
![image](https://user-images.githubusercontent.com/88615790/202982877-ed9d99b0-99ec-4c77-80f2-11ec7ed1ca8e.png)

### 마진 (margin)
결정 경계와 서포트 벡터 사이의 거리 
아래 그림에서 가운데 실선을 기준으로 양 옆 점선과의 거리를 나타낸다. 
![image](https://user-images.githubusercontent.com/88615790/202983180-3a32b424-c733-4a59-ac4c-d2be3c1db179.png)

### Hard Margin Clf 
모든 샘플을 선형적으로 올바르게 분류하고자 하는 경우
데이터가 선형적으로 구분되어야 하면서 이상치에 민감하다. 
오버피팅의 우려가 있다.

### Soft Margin Clf 
margin을 넓게 유지하거나 margin 오류 사이 적정한 균형을 찾는 방법
결정 경계의 폭과 마진오류 사이에 적절한 균형을 잡아준다.  
언더피팅의 우려가 있다.

### Margin Hyper Parameter : Cost(C)
C = 얼마나 많은 데이터 샘플이 다른 클래스에 놓이는 것을 허용하는지를 결정한다.
Sklearn의 SVM모델은 margin을 최대화시키기 위해 C값을 조정할 수 있다. 
결정경계(decision boundary)와 margin의 간격을 지정한다.
C값을 낮게 설정할 경우 유연한 경계면을 만들어 (margin이 넓어짐) 일반적인 결정 경계를 찾는다. (하드 마진)
C값을 높게 설정할 경우 분명하게 경계를 나누어 (margin이 좁아짐) 타이트한 결정 경계를 찾는다. (소프트 마진)

![image](https://user-images.githubusercontent.com/88615790/202983691-aad57488-6214-45b1-a321-229bff3265a9.png)

### 비선형 SVM 
선형 SVM분류기가 효율적이고 많은 경우에 작동하지만, 선형적으로 분류할 수 없는 데이터 셋도 존재한다.
이 경우 다항 특성과 같은 특성을 더 추가하여 선형적으로 구분되는 데이터셋을 만들어줄 수 있다.

#### 비선형 데이터에 SVM적용 방법: 커널 트릭 (Kernel Trick) 
서포트 벡터 머신 알고리즘에 커널 기법을 적용할 경우 비선형적 분류가 가능해진다. 
실제로는 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것과 같은 결과를 얻을 수 있다.  

##### 가우시안 RBF커널 (Radial Basis Funcion, 방사 기저 함수 ) 
![image](https://user-images.githubusercontent.com/88615790/202984269-492940a4-7071-42c9-8b4b-9d7d474f0031.png)

0(랜드마크로부터 멀리 떨어짐)부터 1(랜드마크와 같은 위치)까지 변화하며, 종 모양을 가진다. 
데이터 집합의 모든 점이 가설에 영향을 주며,  데이터 집합의 한 점이 근처에 있는 다른 점에 영향을 미친다.

##### 비선형 데이터 SVM Hyper Parameter : Gamma
유사도 특성을 추가하여 각 샘플이 LandMark와 얼마나 비슷한지를 측정한다. 
가우시간 RBF를 사용한 SVM 모델의 경우, 하이퍼파라미터 Gamma와 C를 조절하여 모델의 복잡도를 조절한다.
Gamma가 커지면 종 모양 그래프가 좁아져서 각 샘플의 영향 범위가 좁아진다.
Gamma가 작아지면 종 모양 그래프가 넓어져서 샘플이 넓은 범위에 걸쳐 영향을 준다.
![image](https://user-images.githubusercontent.com/88615790/202984941-9b1c6eba-913a-47a2-b284-b9b517c27413.png)
